{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6ea957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:19:59.147137Z",
     "start_time": "2024-06-22T05:19:59.144868Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install langdetect googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45c2262f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:19:59.154249Z",
     "start_time": "2024-06-22T05:19:59.149738Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langdetect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangdetect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator, LANGUAGES\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langdetect'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "from googletrans import Translator, LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfbcb6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:24:38.745501Z",
     "start_time": "2024-06-22T05:24:38.700757Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data_Sets/electronics_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c209cb8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:19:59.210520Z",
     "start_time": "2024-06-22T05:19:59.200945Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f4600",
   "metadata": {},
   "source": [
    "# Using Google translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c64396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:21:46.260250Z",
     "start_time": "2024-06-22T05:21:42.938874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the translator\n",
    "translator = Translator()\n",
    "\n",
    "def detect_and_translate(text):\n",
    "    try:\n",
    "        # Detect language\n",
    "        lang = detect(text)\n",
    "        if lang != 'en':\n",
    "            # Translate to English\n",
    "            translated = translator.translate(text, src=lang, dest='en').text\n",
    "            return translated\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Apply the detect_and_translate function to the text column\n",
    "print(df['title'][:5].apply(detect_and_translate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4b912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:21:47.200410Z",
     "start_time": "2024-06-22T05:21:46.262508Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df['text'][:5].apply(detect_and_translate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474bc70",
   "metadata": {},
   "source": [
    "# Using open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d825053",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T04:30:36.627041Z",
     "start_time": "2024-06-22T04:30:36.623933Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade httpx openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2d979ed5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:23:34.258315Z",
     "start_time": "2024-06-22T05:23:26.553974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing text: Hello, how are you?. Error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Error processing text: Bonjour, comment ça va?. Error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Error processing text: Hola, ¿cómo estás?. Error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Error processing text: Hallo, wie geht es dir?. Error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Error processing text: Ciao, come stai?. Error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        Hello, how are you?\n",
       "1    Bonjour, comment ça va?\n",
       "2         Hola, ¿cómo estás?\n",
       "3    Hallo, wie geht es dir?\n",
       "4           Ciao, come stai?\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'sk-proj-qPZr4Y5io2BHaP2LmDPlT3BlbkFJnkgNHZ3O1RMkPlyG5VcU' # from sajjan\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'text': [\n",
    "        'Hello, how are you?',\n",
    "        'Bonjour, comment ça va?',\n",
    "        'Hola, ¿cómo estás?',\n",
    "        'Hallo, wie geht es dir?',\n",
    "        'Ciao, come stai?',\n",
    "        'Buen vendedor'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def detect_and_translate(text):\n",
    "    try:\n",
    "        # Use OpenAI API to determine the language and translate\n",
    "        response = openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            prompt=f\"Detect the language and translate this text to English: '{text}'\",\n",
    "            max_tokens=100\n",
    "        )\n",
    "        translated_text = response.choices[0].text.strip()\n",
    "        return translated_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}. Error: {e}\")\n",
    "        return text\n",
    "\n",
    "# Apply the detect_and_translate function to the text column\n",
    "df['text'][:5].apply(detect_and_translate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f2bce",
   "metadata": {},
   "source": [
    "# Named Entity recognition using matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b833642",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T04:58:08.687363Z",
     "start_time": "2024-06-22T04:57:42.945979Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5af3c928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T04:59:25.707366Z",
     "start_time": "2024-06-22T04:59:25.703432Z"
    }
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "392b5090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T04:59:27.522418Z",
     "start_time": "2024-06-22T04:59:26.683476Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c36e13d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:25:57.339766Z",
     "start_time": "2024-06-22T05:25:56.878626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      []\n",
       "1     [Sound, headphones]\n",
       "2                      []\n",
       "3                      []\n",
       "4                 [Sound]\n",
       "5                      []\n",
       "6               [display]\n",
       "7                      []\n",
       "8                      []\n",
       "9                      []\n",
       "10                     []\n",
       "11                     []\n",
       "12                     []\n",
       "13                     []\n",
       "14                     []\n",
       "15                     []\n",
       "16                     []\n",
       "17                     []\n",
       "18                     []\n",
       "19                     []\n",
       "20                     []\n",
       "21                     []\n",
       "22                     []\n",
       "23                     []\n",
       "24                     []\n",
       "25                     []\n",
       "26                     []\n",
       "27                     []\n",
       "28                     []\n",
       "29                     []\n",
       "30               [camera]\n",
       "31                     []\n",
       "32                     []\n",
       "33                     []\n",
       "34         [sound, sound]\n",
       "35                     []\n",
       "36                     []\n",
       "37                     []\n",
       "38                     []\n",
       "39                     []\n",
       "40                     []\n",
       "41                     []\n",
       "42                     []\n",
       "43                     []\n",
       "44                     []\n",
       "45                     []\n",
       "46                [sound]\n",
       "47                     []\n",
       "48                     []\n",
       "49     [battery, battery]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample dataset\n",
    "# data = {\n",
    "#     'review': [\n",
    "#         'The phone has a great battery life, excellent camera, and loud sound.',\n",
    "#         'I love the bluetooth connectivity of this speaker.',\n",
    "#         'This laptop has an amazing display and the keyboard is very comfortable.',\n",
    "#         'The smartwatch has good battery but the GPS is not accurate.',\n",
    "#         'The headphones have great sound quality and the battery lasts long.'\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# # Create a DataFrame\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# Define product features to look for\n",
    "product_features = [\n",
    "    \"battery\", \"camera\", \"sound\", \"bluetooth\", \"display\", \"keyboard\", \"GPS\", \"headphones\"\n",
    "]\n",
    "\n",
    "# Create a spaCy Matcher instance\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add patterns for each product feature\n",
    "for feature in product_features:\n",
    "    pattern = [{\"LOWER\": feature.lower()}]\n",
    "    matcher.add(feature, [pattern])\n",
    "\n",
    "def extract_features(review):\n",
    "    doc = nlp(review) \n",
    "    matches = matcher(doc)\n",
    "    extracted_features = [doc[start:end].text for match_id, start, end in matches]\n",
    "    return extracted_features\n",
    "\n",
    "# Apply the extract_features function to the review column\n",
    "df['text'][:50].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9cae9d76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:26:41.206653Z",
     "start_time": "2024-06-22T05:26:40.089850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            []\n",
       "1            []\n",
       "2            []\n",
       "3            []\n",
       "4            []\n",
       "5            []\n",
       "6     [display]\n",
       "7            []\n",
       "8            []\n",
       "9            []\n",
       "10           []\n",
       "11           []\n",
       "12           []\n",
       "13           []\n",
       "14           []\n",
       "15           []\n",
       "16           []\n",
       "17           []\n",
       "18           []\n",
       "19           []\n",
       "20           []\n",
       "21           []\n",
       "22           []\n",
       "23           []\n",
       "24           []\n",
       "25           []\n",
       "26           []\n",
       "27           []\n",
       "28           []\n",
       "29           []\n",
       "30     [camera]\n",
       "31           []\n",
       "32           []\n",
       "33           []\n",
       "34      [sound]\n",
       "35           []\n",
       "36           []\n",
       "37           []\n",
       "38           []\n",
       "39           []\n",
       "40           []\n",
       "41           []\n",
       "42           []\n",
       "43           []\n",
       "44           []\n",
       "45           []\n",
       "46      [sound]\n",
       "47           []\n",
       "48           []\n",
       "49    [battery]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "# Define keywords related to product features\n",
    "product_keywords = {\n",
    "    'phone': ['battery', 'camera', 'sound', 'bluetooth'],\n",
    "    'speaker': ['bluetooth', 'sound', 'connectivity'],\n",
    "    'laptop': ['display', 'keyboard', 'battery'],\n",
    "    'smartwatch': ['battery', 'GPS'],\n",
    "    'headphones': ['sound', 'battery']\n",
    "}\n",
    "\n",
    "def extract_product_features(text):\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Initialize an empty list to store extracted features\n",
    "    features = []\n",
    "\n",
    "    # Iterate over entities and tokens in the document\n",
    "    for ent in doc.ents:\n",
    "        # Check if the entity label is related to products or organizations\n",
    "        if ent.label_ in ['PRODUCT', 'ORG']:\n",
    "            # Check if the entity text is a product keyword\n",
    "            if ent.text.lower() in product_keywords:\n",
    "                features.extend(product_keywords[ent.text.lower()])\n",
    "\n",
    "    # Iterate over tokens in the document\n",
    "    for token in doc:\n",
    "        # Check if the token is a noun and not a stop word\n",
    "        if token.pos_ == 'NOUN' and not token.is_stop:\n",
    "            # Check if the token text is a product keyword\n",
    "            for product, keywords in product_keywords.items():\n",
    "                if token.text.lower() in keywords:\n",
    "                    features.append(token.text)\n",
    "                    break\n",
    "\n",
    "    return list(set(features))  # Return unique features\n",
    "\n",
    "# Apply the extract_product_features function to the review column\n",
    "df['text'][:50].apply(extract_product_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2c3eb39d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T06:01:03.399151Z",
     "start_time": "2024-06-22T06:01:03.396948Z"
    }
   },
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a4524c4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T06:05:32.489541Z",
     "start_time": "2024-06-22T06:05:32.477566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I LOVE my Amazon 4K Fire Stick!!!  My TV is only 5 years old but already out of date!  I couldn’t load any new apps but now I do it all on my Fire Stick, and I have only had a brief pause in streaming once, most likely due to my wifi connection.  I like it so much I have purchased a second one for one of my other TVs and I have recommended it to so many friends who were having the same issues I was with their relatively new, yet “old” TV.  Since I already have an echo dot in my room, I just tell Alexa what I want on the TV and she does it!  Definitely one of my best purchases for 2020!!!!\n",
      "['Amazon', 'Fire', 'Stick', 'TV', 'years', 'date', 't', 'load', 'apps', 'Fire', 'Stick', 'pause', 'connection', 'TVs', 'friends', 'issues', 'TV', 'dot', 'room', 'Alexa', 'TV', 'purchases']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "lines = df[\"text\"][5]\n",
    "print(lines)\n",
    "# function to test if something is a noun\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "# do the nlp stuff\n",
    "tokenized = nltk.word_tokenize(lines)\n",
    "nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n",
    "\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9c3f35e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T06:19:06.148598Z",
     "start_time": "2024-06-22T06:19:04.706946Z"
    }
   },
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract the product name and top 3 features from the following review:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mreview_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProduct:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Call OpenAI GPT-3 API\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     18\u001b[0m     engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# or use \"text-davinci-003\" for GPT-3.5\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     20\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,  \u001b[38;5;66;03m# Adjust as necessary\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mapi_key\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Parse the response to extract product name and features\u001b[39;00m\n\u001b[1;32m     25\u001b[0m output \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    712\u001b[0m             result\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Your OpenAI API key\n",
    "api_key = 'sk-proj-qPZr4Y5io2BHaP2LmDPlT3BlbkFJnkgNHZ3O1RMkPlyG5VcU'\n",
    "\n",
    "# Review text\n",
    "review_text = \"\"\"\n",
    "I LOVE my iPhone 12 Pro Max!!! The camera quality is incredible, the battery life lasts all day, \n",
    "and the performance is blazing fast. I upgraded from an older model and couldn't be happier. \n",
    "Definitely worth the investment!\n",
    "\"\"\"\n",
    "\n",
    "# OpenAI GPT-3 prompt\n",
    "prompt = f\"Extract the product name and top 3 features from the following review:\\n{review_text}\\nProduct:\"\n",
    "\n",
    "# Call OpenAI GPT-3 API\n",
    "response = openai.Completion.create(\n",
    "    engine=\"GPT-3.5\",  # or use \"text-davinci-003\" for GPT-3.5\n",
    "    prompt=prompt,\n",
    "    max_tokens=150,  # Adjust as necessary\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# Parse the response to extract product name and features\n",
    "output = response.choices[0].text.strip().split('\\n')\n",
    "product_name = output[0]\n",
    "features = [feat.strip('- ') for feat in output[1:4]]  # Extract top 3 features\n",
    "\n",
    "print(f\"Product: {product_name}\")\n",
    "print(\"Top 3 features:\")\n",
    "for feature in features:\n",
    "    print(f\"- {feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b54d36c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T06:24:10.773878Z",
     "start_time": "2024-06-22T06:24:10.771407Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aed378ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:06:46.069888Z",
     "start_time": "2024-06-22T09:06:45.955961Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoTokenizer' from 'transformers' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load model directly\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescribeai/gemini-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescribeai/gemini-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AutoTokenizer' from 'transformers' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"describeai/gemini-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"describeai/gemini-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4f3c9dce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:40:57.082422Z",
     "start_time": "2024-06-22T09:40:56.965261Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pipeline' from 'transformers' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use a pipeline as a high-level helper\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      4\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext2text-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescribeai/gemini-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pipeline' from 'transformers' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=\"describeai/gemini-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0b2300ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:34:28.767639Z",
     "start_time": "2024-06-22T09:34:28.764912Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e7be1d9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:40:53.104633Z",
     "start_time": "2024-06-22T09:40:53.086329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('carrying an Inreach', 0.012849913978126995)\n",
      "('spent several years', 0.031243910890458804)\n",
      "('years carrying', 0.031243910890458804)\n",
      "('Inreach', 0.07288751237548687)\n",
      "('nightmare', 0.07934818494128172)\n",
      "('unreliable this device', 0.1705844289713273)\n",
      "('spent', 0.17406120936370134)\n",
      "('years', 0.17406120936370134)\n",
      "('carrying', 0.17406120936370134)\n",
      "('hard', 0.17406120936370134)\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "text = \"\"\"I have spent several years carrying an Inreach and it is hard to believe how unreliable this device is. Updating firmware is a nightmare. Syncing, nightmare. User Interface is clunky. Getting a computer to both use the sync/update software and actually see the device plugged in via USB is a nightmare. You can either go with a less robust satellite beacon or go full satellite phone - either is a more reliable alternative.\"\"\"\n",
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_threshold = 0.9\n",
    "numOfKeywords = 10\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "keywords = custom_kw_extractor.extract_keywords(text)\n",
    "for kw in keywords:\n",
    "    print(kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d9efc669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:48:21.883114Z",
     "start_time": "2024-06-22T09:48:11.302282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/quicktech/anaconda3/lib/python3.11/site-packages/huggingface_hub-0.22.0rc0-py3.8.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting summa\n",
      "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from summa) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from scipy>=0.19->summa) (1.24.4)\n",
      "Building wheels for collected packages: summa\n",
      "  Building wheel for summa (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54388 sha256=ad87ddba2544482a9e35cfc01530e00b09be73b0e2b3af5aaaf034fcd218ba57\n",
      "  Stored in directory: /Users/quicktech/Library/Caches/pip/wheels/10/2d/7a/abce87c4ea233f8dcca0d99b740ac0257eced1f99a124a0e1f\n",
      "Successfully built summa\n",
      "Installing collected packages: summa\n",
      "Successfully installed summa-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c5a3f003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:49:26.290838Z",
     "start_time": "2024-06-22T09:49:26.282989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('new', 0.2982219516463651), ('k', 0.20433726316510273)]\n"
     ]
    }
   ],
   "source": [
    "from summa import keywords\n",
    "text = \"\"\"I LOVE my Amazon 4K Fire Stick!!!  My TV is only 5 years old but already out of date!  I couldn‚Äôt load any new apps but now I do it all on my Fire Stick, and I have only had a brief pause in streaming once, most likely due to my wifi connection.  I like it so much I have purchased a second one for one of my other TVs and I have recommended it to so many friends who were having the same issues I was with their relatively new, yet ‚Äúold‚Äù TV.  Since I already have an echo dot in my room, I just tell Alexa what I want on the TV and she does it!  Definitely one of my best purchases for 2020!!!!\"\"\"\n",
    "TR_keywords = keywords.keywords(text, scores=True)\n",
    "print(TR_keywords[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c1fab455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:57:05.268374Z",
     "start_time": "2024-06-22T09:56:56.218044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/quicktech/anaconda3/lib/python3.11/site-packages/huggingface_hub-0.22.0rc0-py3.8.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: keybert in /Users/quicktech/anaconda3/lib/python3.11/site-packages (0.8.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from keybert) (1.24.4)\n",
      "Requirement already satisfied: rich>=10.4.0 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from keybert) (12.4.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from keybert) (1.3.0)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from keybert) (3.0.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from rich>=10.4.0->keybert) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from rich>=10.4.0->keybert) (2.15.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22.2->keybert) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22.2->keybert) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22.2->keybert) (2.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (4.41.2)\n",
      "Requirement already satisfied: tqdm in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/quicktech/anaconda3/lib/python3.11/site-packages/huggingface_hub-0.22.0rc0-py3.8.egg (from sentence-transformers>=0.3.8->keybert) (0.22.0rc0)\n",
      "Requirement already satisfied: Pillow in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (10.2.0)\n",
      "Requirement already satisfied: filelock in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.3)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers>=0.3.8->keybert)\n",
      "  Obtaining dependency information for huggingface-hub>=0.15.1 from https://files.pythonhosted.org/packages/69/d6/73f9d1b7c4da5f0544bc17680d0fa9932445423b90cd38e1ee77d001a4f5/huggingface_hub-0.23.4-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->keybert) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->keybert) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=0.3.8->keybert) (0.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.3.8->keybert) (2024.6.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/quicktech/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
      "Using cached huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.23.4\n",
      "    Uninstalling huggingface-hub-0.23.4:\n",
      "      Successfully uninstalled huggingface-hub-0.23.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ludwig 0.9.3 requires fsspec[http]<=2023.10.0, but you have fsspec 2024.3.1 which is incompatible.\n",
      "ludwig 0.9.3 requires psutil==5.9.4, but you have psutil 5.9.0 which is incompatible.\n",
      "ludwig 0.9.3 requires PyYAML!=5.4.*,<6.0.1,>=3.12, but you have pyyaml 6.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b0a0d55a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T09:56:45.650212Z",
     "start_time": "2024-06-22T09:56:45.447100Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoConfig' from 'transformers' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[176], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeybert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyBERT\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keybert/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeybert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_llm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyLLM\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeybert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyBERT\n\u001b[1;32m      6\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeybert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keybert/_llm.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Union\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[1;32m      5\u001b[0m     HAS_SBERT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm, trange\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, is_torch_npu_available\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AutoConfig' from 'transformers' (unknown location)"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c3945f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T11:42:50.027047Z",
     "start_time": "2024-06-22T11:42:48.937959Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "23a137d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T11:47:13.376177Z",
     "start_time": "2024-06-22T11:47:13.345190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOVE ORG\n",
      "Amazon 4K Fire Stick ORG\n",
      "only 5 years old DATE\n",
      "Fire Stick FAC\n",
      "second ORDINAL\n",
      "one CARDINAL\n",
      "one CARDINAL\n",
      "‚ PERSON\n",
      "Alexa ORG\n",
      "2020 DATE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    LOVE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " my \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon 4K Fire Stick\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "!!!  My TV is \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    only 5 years old\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " but already out of date!  I couldn‚Äôt load any new apps but now I do it all on my \n",
       "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fire Stick\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       ", and I have only had a brief pause in streaming once, most likely due to my wifi connection.  I like it so much I have purchased a \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of my other TVs and I have recommended it to so many friends who were having the same issues I was with their relatively new, yet \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ‚\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "Äúold‚Äù TV.  Since I already have an echo dot in my room, I just tell \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alexa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " what I want on the TV and she does it!  Definitely one of my best purchases for \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "!!!!</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_text=\"I LOVE my Amazon 4K Fire Stick!!!  My TV is only 5 years old but already out of date!  I couldn‚Äôt load any new apps but now I do it all on my Fire Stick, and I have only had a brief pause in streaming once, most likely due to my wifi connection.  I like it so much I have purchased a second one for one of my other TVs and I have recommended it to so many friends who were having the same issues I was with their relatively new, yet ‚Äúold‚Äù TV.  Since I already have an echo dot in my room, I just tell Alexa what I want on the TV and she does it!  Definitely one of my best purchases for 2020!!!!\"\n",
    "\n",
    "text1= NER(raw_text)\n",
    "\n",
    "# Now, we print the data on the NEs found in this text sample.\n",
    "\n",
    "for word in text1.ents:\n",
    "    print(word.text,word.label_)\n",
    "displacy.render(text1,style=\"ent\",jupyter=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4942e7ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T11:46:53.565556Z",
     "start_time": "2024-06-22T11:46:53.545679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "several years DATE\n",
      "Inreach PERSON\n",
      "Interface ORG\n",
      "USB ORG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I have spent \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    several years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " carrying an \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Inreach\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and it is hard to believe how unreliable this device is. Updating firmware is a nightmare. Syncing, nightmare. User \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Interface\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is clunky. Getting a computer to both use the sync/update software and actually see the device plugged in via \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    USB\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is a nightmare. You can either go with a less robust satellite beacon or go full satellite phone - either is a more reliable alternative.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_text=\"I have spent several years carrying an Inreach and it is hard to believe how unreliable this device is. Updating firmware is a nightmare. Syncing, nightmare. User Interface is clunky. Getting a computer to both use the sync/update software and actually see the device plugged in via USB is a nightmare. You can either go with a less robust satellite beacon or go full satellite phone - either is a more reliable alternative.\"\n",
    "\n",
    "\n",
    "text1= NER(raw_text)\n",
    "\n",
    "# Now, we print the data on the NEs found in this text sample.\n",
    "\n",
    "for word in text1.ents:\n",
    "    print(word.text,word.label_)\n",
    "displacy.render(text1,style=\"ent\",jupyter=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ecdbd780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T11:46:42.186512Z",
     "start_time": "2024-06-22T11:46:42.172119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second ORDINAL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Sound is good quality. I like it that although I only bought one set of headphones the charger has an option for a \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " set incase I want to buy another one.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_text=\"Sound is good quality. I like it that although I only bought one set of headphones the charger has an option for a second set incase I want to buy another one.\"\n",
    "\n",
    "\n",
    "text1= NER(raw_text)\n",
    "\n",
    "# Now, we print the data on the NEs found in this text sample.\n",
    "\n",
    "for word in text1.ents:\n",
    "    print(word.text,word.label_)\n",
    "displacy.render(text1,style=\"ent\",jupyter=True)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
